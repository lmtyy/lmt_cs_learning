好的，我们来详细讲解吴恩达（Andrew Ng）在他的机器学习课程（尤其是著名的Coursera课程和CS229讲义）中阐述的无监督异常检测方法。他的方法论非常经典、直观，并且具有很强的实践指导意义。

### 核心思想：基于高斯分布的参数化模型

吴恩达教授的方法核心是**使用参数化的高斯分布来对正常数据的特征进行建模**。这是一种典型的**参数统计方法**，其基本流程可以概括为：

1.  **选择特征**：选择能够区分正常和异常行为的关键特征。
2.  **拟合模型**：用正常数据（或无标签数据，假设其中大部分是正常的）来为每个特征拟合一个高斯分布。
3.  **密度估计**：对于一个新的测试点，计算它由这个“正常模型”生成的概率。
4.  **设置阈值**：如果概率低于某个阈值，则将其标记为异常。

---

### 详细步骤与数学原理

#### 第1步：选择特征

这是最关键的一步。成功的异常检测依赖于选择那些在异常情况下会表现出“异常”值的特征。

*   **示例**：在监控服务器性能时，可能会选择：
    *   `CPU_load`
    *   `Memory_usage`
    *   `Network_traffic`
    *   `Requests_per_second`
*   **技巧**：如果特征不服从大致的高斯分布，可以尝试进行**变换**，例如取对数（`log(x)`）、平方根（`sqrt(x)`）等，使其分布更接近钟形曲线，以便高斯模型能更好地拟合。

#### 第2步：拟合高斯分布

假设我们有 \( m \) 个正常训练样本，每个样本有 \( n \) 个特征。对于每一个特征 \( j \)，我们假设它服从一个高斯分布（正态分布）：

\[
x_j \sim \mathcal{N}(\mu_j, \sigma_j^2)
\]

我们需要从训练数据中估计出每个特征的高斯参数（均值和方差）：

*   **均值** \( \mu_j \)：
    \[
    \mu_j = \frac{1}{m} \sum_{i=1}^{m} x_j^{(i)}
    \]
*   **方差** \( \sigma_j^2 \)：
    \[
    \sigma_j^2 = \frac{1}{m} \sum_{i=1}^{m} (x_j^{(i)} - \mu_j)^2
    \]

这里使用的是总体方差的有偏估计（分母为 \( m \)），在机器学习中很常见，当 \( m \) 很大时，与样本方差（分母为 \( m-1 \)）差异很小。

#### 第3步：计算概率与异常分数

对于一个新样本 \( x \)，我们想要计算它属于“正常”数据的概率。我们做一个**朴素贝叶斯假设**：即所有特征之间是相互独立的。

在这个假设下，样本 \( x \) 的联合概率密度就是每个特征概率密度的乘积：

\[
p(x) = \prod_{j=1}^{n} p(x_j; \mu_j, \sigma_j^2) = \prod_{j=1}^{n} \frac{1}{\sqrt{2\pi}\sigma_j} \exp\left(-\frac{(x_j - \mu_j)^2}{2\sigma_j^2}\right)
\]

**异常检测函数** 由此定义：

1.  计算 \( p(x) \)。
2.  如果 \( p(x) < \epsilon \)，则判定为异常。

**实际操作中的改进：使用对数概率**

由于多个小概率值连乘可能导致数值下溢（得到一个极小的、不精确的数），我们通常计算**对数概率**，它将连乘变为连加：

\[
\log p(x) = \sum_{j=1}^{n} \log p(x_j; \mu_j, \sigma_j^2) = -\frac{n}{2} \log(2\pi) - \sum_{j=1}^{n} (\log \sigma_j) - \frac{1}{2} \sum_{j=1}^{n} \frac{(x_j - \mu_j)^2}{\sigma_j^2}
\]

在实际判断时，我们比较 `log p(x)` 和 `log ε`。因为 `log` 是单调递增函数，所以 `p(x) < ε` 等价于 `log p(x) < log ε`。

**另一种视角：异常分数**

我们也可以定义一个**异常分数**，这个分数越高，代表越可能是异常。一个自然的选择是使用负对数概率：

\[
\text{anomaly\_score}(x) = -\log p(x)
\]

然后，我们设置一个阈值 \( \epsilon \) ，如果 `anomaly_score(x) > ε`，则判定为异常。

#### 第4步：如何选择阈值 \( \epsilon \) 

这是连接模型和业务需求的关键一步。吴恩达教授介绍了如何使用一个**带标签的交叉验证集**来选择 \( \epsilon \)，即使我们的训练数据是无标签的，在实践中我们通常也能获得一小部分带有“异常”标签的数据用于调参。

**步骤**：

1.  准备一个**交叉验证集**，其中包含一些已知是正常和异常的数据点。例如：`cv_data = {(x₁, y₁), (x₂, y₂), ...}`，其中 `y=0` 表示正常，`y=1` 表示异常。
2.  在训练集（无标签）上拟合高斯模型。
3.  在交叉验证集上，对每个样本计算 `p(x)` 或 `anomaly_score(x)`。
4.  尝试多个可能的 \( \epsilon \) 值，对于每个 \( \epsilon \)：
    *   预测：如果 `p(x) < ε`，则 `y_pred = 1`（异常），否则 `y_pred = 0`（正常）。
    *   根据CV集上的真实标签 `y`，计算评估指标。
5.  选择在CV集上**表现最好**的 \( \epsilon \)。

**选择 \( \epsilon \) 的评估指标**：

*   **F1分数**：精确率和召回率的调和平均数。这是非常推荐的指标，因为它能在精确率（误报要少）和召回率（异常要尽可能找出来）之间取得平衡。
*   也可以考虑精确率和召回率本身，但需要根据业务目标权衡（例如，在金融风控中，我们可能宁愿误报也要保证高召回率）。

---

### 与多元高斯分布模型的对比

吴恩达的课程中也简要介绍了**多元高斯分布**方法，并解释了其与上述方法的区别。

| 方面           | 原始模型（特征独立）                                         | 多元高斯模型                                                 |
| :------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| **核心假设**   | 特征之间**相互独立**                                         | 特征之间**可以相关**，通过协方差矩阵 \( \Sigma \) 捕捉       |
| **模型**       | \( p(x) = \prod_{j=1}^{n} p(x_j; \mu_j, \sigma_j^2) \)       | \( p(x) = \frac{1}{(2\pi)^{n/2}                              |
| **参数数量**   | \( 2n \) （线性增长）                                        | \( n + n(n+1)/2 \) （平方增长）                              |
| **计算效率**   | 高，可很好地进行规模缩放                                     | 低，计算 \( \Sigma^{-1} \) 和 \( \|\Sigma\| \) 成本高        |
| **数据要求**   | 对训练数据量 \( m \) 要求不高                                | 需要 \( m > n \)（最好 \( m > 10n \)），否则 \( \Sigma \) 不可逆 |
| **捕捉相关性** | **不能**。必须手动创建新特征（如 `CPU_load / Memory_usage`）来捕捉关系 | **能**。自动捕捉特征之间的线性相关性                         |

**使用建议**：
*   **默认使用原始模型**。它在实践中非常有效，即使特征间有轻微相关性也能工作得很好。
*   只有当你想**自动捕捉特征之间的相关性**，并且有**充足的数据**（`m >> n`）保证协方差矩阵可逆时，才考虑使用多元高斯模型。如果 `m < n`，则不能使用多元高斯模型。

---

### 总结：吴恩达方法的优势与流程

**优势**：
1.  **直观易懂**：基于概率，有清晰的统计解释。
2.  **计算高效**：训练和预测的速度都非常快。
3.  **易于实现**：算法简单，代码编写直接。
4.  **对小数据集友好**：即使训练数据不多，也能工作得很好。
5.  **实践导向**：提供了如何选择阈值 \( \epsilon \) 的系统方法，将算法与实际评估联系起来。

**标准工作流程**：
1.  **准备数据**：从无标签数据中划分出训练集、交叉验证集（最好带标签）和测试集。
2.  **训练模型**：在训练集上，为每个特征计算 \( \mu_j \) 和 \( \sigma_j^2 \)。
3.  **调参**：在交叉验证集上，通过评估指标（如F1分数）来选择最佳阈值 \( \epsilon \)。
4.  **评估**：在测试集上最终评估模型的性能。
5.  **部署**：将训练好的模型（参数 \( \mu_j \), \( \sigma_j^2 \), \( \epsilon \) ）部署到生产环境中进行实时异常检测。

这种方法为初学者和从业者提供了一个强大而可靠的基线模型，在许多实际应用场景中，它的表现足以媲美甚至超过更复杂的算法。